"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[4576],{5368:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-3-ai-robot-brain/navigation-path-planning-isaac","title":"Navigation and Path Planning with NVIDIA Isaac","description":"For a mobile robot to be autonomous, it must be able to navigate its environment safely and efficiently. This involves three core capabilities:","source":"@site/docs/module-3-ai-robot-brain/navigation-path-planning-isaac.mdx","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/navigation-path-planning-isaac","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module-3-ai-robot-brain/navigation-path-planning-isaac","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"sidebar_label":"Navigation and Path Planning"},"sidebar":"mainSidebar","previous":{"title":"Pose Estimation and Tracking","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/docs/module-3-ai-robot-brain/pose-estimation-tracking"},"next":{"title":"Module 4: Vision-Language-Action (VLA)","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/docs/category/module-4-vision-language-action-vla"}}');var o=a(4848),t=a(8453);const s={sidebar_label:"Navigation and Path Planning"},r="Navigation and Path Planning with NVIDIA Isaac",l={},c=[{value:"The Robotics Navigation Stack",id:"the-robotics-navigation-stack",level:2},{value:"Navigation in Isaac Sim",id:"navigation-in-isaac-sim",level:2},{value:"Step-by-Step Example: Running a Navigation Demo",id:"step-by-step-example-running-a-navigation-demo",level:2}];function h(n){const e={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"navigation-and-path-planning-with-nvidia-isaac",children:"Navigation and Path Planning with NVIDIA Isaac"})}),"\n",(0,o.jsx)(e.p,{children:"For a mobile robot to be autonomous, it must be able to navigate its environment safely and efficiently. This involves three core capabilities:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Mapping:"})," Building a map of the environment."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Localization:"})," Knowing where it is within that map."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Path Planning:"})," Finding a collision-free path from its current location to a goal location."]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"The NVIDIA Isaac platform provides a complete, hardware-accelerated navigation stack that integrates seamlessly with ROS 2, making it easier than ever to get your robot moving autonomously."}),"\n",(0,o.jsx)(e.h2,{id:"the-robotics-navigation-stack",children:"The Robotics Navigation Stack"}),"\n",(0,o.jsx)(e.p,{children:"A typical navigation stack, like the popular ROS 2 Nav2 project, is a complex system of interconnected nodes. Here's a simplified overview:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"SLAM (Simultaneous Localization and Mapping):"})," This process is used to build a map of an unknown environment while simultaneously keeping track of the robot's position within it. Isaac ROS provides GPU-accelerated SLAM packages."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Localization (AMCL):"})," Once a map is created, the robot uses Adaptive Monte Carlo Localization (AMCL) to determine its position and orientation on the map based on sensor data (like a laser scanner). Isaac ROS also provides an accelerated version of this."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Global Planner:"})," Given a goal location on the map, the global planner finds a high-level path from the robot's current position to the goal, avoiding known obstacles on the map."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Local Planner:"})," The local planner is responsible for generating motor commands to follow the global plan while avoiding immediate, dynamic obstacles that may not be on the map (like a person walking by)."]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"NVIDIA has taken the core algorithms from the robust and community-supported Nav2 stack and created GPU-accelerated versions of them in Isaac ROS, leading to significant performance improvements."}),"\n",(0,o.jsx)(e.h2,{id:"navigation-in-isaac-sim",children:"Navigation in Isaac Sim"}),"\n",(0,o.jsx)(e.p,{children:"Isaac Sim is the perfect tool for developing and testing your navigation stack. You can:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Build Custom Worlds:"})," Create complex, large-scale environments that mimic the real world where your robot will be deployed."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Simulate Sensors:"})," Accurately simulate the sensors required for navigation, such as 2D and 3D Lidars, and RGB-D cameras."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Test Scenarios:"})," Easily test your robot's ability to handle challenging scenarios, like cluttered hallways, dynamic obstacles, and large open spaces, without risking damage to a physical robot."]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"step-by-step-example-running-a-navigation-demo",children:"Step-by-Step Example: Running a Navigation Demo"}),"\n",(0,o.jsx)(e.p,{children:"Let's walk through how to run a navigation demo with a Carter robot in a simulated warehouse."}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Launch Isaac Sim:"})," Start Isaac Sim from the Omniverse Launcher."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Open the Navigation Scene:"})," Open the ",(0,o.jsx)(e.code,{children:"Isaac/Samples/ROS/Scenes/carter_warehouse_navigation.usd"})," scene. This loads a large warehouse environment and a Carter robot equipped with a Lidar."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Start the ROS2 Bridge:"})," Ensure the ROS2 bridge is enabled (",(0,o.jsx)(e.code,{children:"Window > ROS Bridge"}),")."]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Launch the Navigation Stack:"})," In a terminal, source your ROS2 workspace and launch the Isaac ROS navigation launch file:"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",children:"ros2 launch isaac_ros_nav2 isaac_ros_nav2.launch.py\n"})}),"\n",(0,o.jsx)(e.p,{children:"This command launches all the necessary nodes: the accelerated SLAM or localization nodes, the global planner, the local planner, and more."}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Control and Monitor in RViz2:"})," In another terminal, launch RViz2 with the Nav2 configuration:"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",children:"ros2 run rviz2 rviz2 -d $(ros2 pkg prefix isaac_ros_nav2)/rviz/isaac_ros_nav2.rviz\n"})}),"\n",(0,o.jsx)(e.p,{children:"In RViz2, you will see:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"The map being built by the SLAM algorithm (or the pre-loaded map)."}),"\n",(0,o.jsx)(e.li,{children:"The robot's position on the map."}),"\n",(0,o.jsx)(e.li,{children:"The costmaps used by the planners."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(e.li,{children:["\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Set a Goal:"}),' Use the "Nav2 Goal" tool in the RViz2 toolbar to click on a location on the map. The robot will begin planning and executing a path to that goal, avoiding obstacles along the way.']}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"By using the Isaac ROS navigation stack, you can achieve robust and high-performance autonomous navigation for your robot, with the ability to thoroughly test and validate your system in a realistic simulation before deploying it in the real world."})]})}function d(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(h,{...n})}):h(n)}},8453:(n,e,a)=>{a.d(e,{R:()=>s,x:()=>r});var i=a(6540);const o={},t=i.createContext(o);function s(n){const e=i.useContext(t);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),i.createElement(t.Provider,{value:e},n.children)}}}]);