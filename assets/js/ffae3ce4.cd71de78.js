"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[4576],{5368:(n,t,a)=>{a.r(t),a.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>p,frontMatter:()=>r,metadata:()=>o,toc:()=>l});const o=JSON.parse('{"id":"module-3-ai-robot-brain/navigation-path-planning-isaac","title":"navigation-path-planning-isaac","description":"","source":"@site/docs/module-3-ai-robot-brain/navigation-path-planning-isaac.mdx","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/navigation-path-planning-isaac","permalink":"/ai-book-hackathon/module-3-ai-robot-brain/navigation-path-planning-isaac","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"mainSidebar","previous":{"title":"pose-estimation-tracking","permalink":"/ai-book-hackathon/module-3-ai-robot-brain/pose-estimation-tracking"},"next":{"title":"Module 4: Vision-Language-Action (VLA)","permalink":"/ai-book-hackathon/category/module-4-vision-language-action-vla"}}');var e=a(4848),i=a(8453);const r={},s=void 0,c={},l=[];function u(n){return(0,e.jsx)(e.Fragment,{})}function p(n={}){const{wrapper:t}={...(0,i.R)(),...n.components};return t?(0,e.jsx)(t,{...n,children:(0,e.jsx)(u,{...n})}):u()}},8453:(n,t,a)=>{a.d(t,{R:()=>r,x:()=>s});var o=a(6540);const e={},i=o.createContext(e);function r(n){const t=o.useContext(i);return o.useMemo(function(){return"function"==typeof n?n(t):{...t,...n}},[t,n])}function s(n){let t;return t=n.disableParentContext?"function"==typeof n.components?n.components(e):n.components||e:r(n.components),o.createElement(i.Provider,{value:t},n.children)}}}]);