"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[2745],{8453:(e,o,s)=>{s.d(o,{R:()=>a,x:()=>t});var r=s(6540);const n={},i=r.createContext(n);function a(e){const o=r.useContext(i);return r.useMemo(function(){return"function"==typeof e?e(o):{...o,...e}},[o,e])}function t(e){let o;return o=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:a(e.components),r.createElement(i.Provider,{value:o},e.children)}},9539:(e,o,s)=>{s.r(o),s.d(o,{assets:()=>l,contentTitle:()=>t,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"module-4-vla/vla-frameworks-apis","title":"Frameworks and APIs for Vision-Language-Action Models","description":"Building and deploying a Vision-Language-Action (VLA) model is a complex undertaking that requires a sophisticated stack of software tools. In this section, we will provide an overview of the key frameworks and APIs that are driving the development of VLA models.","source":"@site/docs/module-4-vla/vla-frameworks-apis.mdx","sourceDirName":"module-4-vla","slug":"/module-4-vla/vla-frameworks-apis","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/module-4-vla/vla-frameworks-apis","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"sidebar_label":"VLA Frameworks and APIs"},"sidebar":"mainSidebar","previous":{"title":"Action Generation","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/module-4-vla/action-generation"},"next":{"title":"Ethical Considerations","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/module-4-vla/ethical-considerations"}}');var n=s(4848),i=s(8453);const a={sidebar_label:"VLA Frameworks and APIs"},t="Frameworks and APIs for Vision-Language-Action Models",l={},d=[{value:"General-Purpose Deep Learning Frameworks",id:"general-purpose-deep-learning-frameworks",level:2},{value:"PyTorch",id:"pytorch",level:3},{value:"TensorFlow",id:"tensorflow",level:3},{value:"Robotics-Specific VLA Frameworks",id:"robotics-specific-vla-frameworks",level:2},{value:"NVIDIA Isaac Sim and Isaac ROS",id:"nvidia-isaac-sim-and-isaac-ros",level:3},{value:"Google&#39;s Robotics Transformer (RT-1 and RT-2)",id:"googles-robotics-transformer-rt-1-and-rt-2",level:3},{value:"Other Notable Frameworks",id:"other-notable-frameworks",level:3}];function c(e){const o={h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(o.header,{children:(0,n.jsx)(o.h1,{id:"frameworks-and-apis-for-vision-language-action-models",children:"Frameworks and APIs for Vision-Language-Action Models"})}),"\n",(0,n.jsx)(o.p,{children:"Building and deploying a Vision-Language-Action (VLA) model is a complex undertaking that requires a sophisticated stack of software tools. In this section, we will provide an overview of the key frameworks and APIs that are driving the development of VLA models."}),"\n",(0,n.jsx)(o.p,{children:"These tools can be broadly categorized into two groups:"}),"\n",(0,n.jsxs)(o.ol,{children:["\n",(0,n.jsxs)(o.li,{children:[(0,n.jsx)(o.strong,{children:"General-Purpose Deep Learning Frameworks:"})," These are the foundational libraries for building and training neural networks."]}),"\n",(0,n.jsxs)(o.li,{children:[(0,n.jsx)(o.strong,{children:"Robotics-Specific VLA Frameworks:"})," These are more recent, specialized frameworks that are designed to address the unique challenges of robotics."]}),"\n"]}),"\n",(0,n.jsx)(o.h2,{id:"general-purpose-deep-learning-frameworks",children:"General-Purpose Deep Learning Frameworks"}),"\n",(0,n.jsxs)(o.p,{children:["At the core of any VLA model is a deep neural network. The two most popular open-source frameworks for building these networks are ",(0,n.jsx)(o.strong,{children:"PyTorch"})," and ",(0,n.jsx)(o.strong,{children:"TensorFlow"}),"."]}),"\n",(0,n.jsx)(o.h3,{id:"pytorch",children:"PyTorch"}),"\n",(0,n.jsx)(o.p,{children:(0,n.jsx)(o.img,{src:"https://pytorch.org/assets/images/pytorch-logo.png",alt:"PyTorch Logo"})}),"\n",(0,n.jsx)(o.p,{children:"PyTorch, developed by Facebook's AI Research lab (FAIR), has become the preferred framework for many researchers in the AI and robotics communities. Its key features include:"}),"\n",(0,n.jsxs)(o.ul,{children:["\n",(0,n.jsxs)(o.li,{children:[(0,n.jsx)(o.strong,{children:"Python-first:"})," PyTorch has a simple, Pythonic interface that is easy to learn and use."]}),"\n",(0,n.jsxs)(o.li,{children:[(0,n.jsx)(o.strong,{children:"Dynamic Computation Graph:"}),' PyTorch\'s "define-by-run" approach makes it very flexible and easy to debug.']}),"\n",(0,n.jsxs)(o.li,{children:[(0,n.jsx)(o.strong,{children:"Strong Community:"})," PyTorch has a large and active community, with a rich ecosystem of tools and libraries."]}),"\n"]}),"\n",(0,n.jsx)(o.h3,{id:"tensorflow",children:"TensorFlow"}),"\n",(0,n.jsx)(o.p,{children:(0,n.jsx)(o.img,{src:"https://www.tensorflow.org/images/tf_logo_social.png",alt:"TensorFlow Logo"})}),"\n",(0,n.jsx)(o.p,{children:"TensorFlow, developed by Google, is another powerful and widely used deep learning framework. It is known for its scalability and production-readiness."}),"\n",(0,n.jsxs)(o.ul,{children:["\n",(0,n.jsxs)(o.li,{children:[(0,n.jsx)(o.strong,{children:"Scalability:"})," TensorFlow is designed to scale from research to production, and it can be deployed on a wide variety of platforms, from mobile devices to large-scale distributed systems."]}),"\n",(0,n.jsxs)(o.li,{children:[(0,n.jsx)(o.strong,{children:"Ecosystem:"})," TensorFlow has a mature ecosystem of tools, including TensorBoard for visualization and TensorFlow Serving for deploying models in production."]}),"\n",(0,n.jsxs)(o.li,{children:[(0,n.jsx)(o.strong,{children:"Keras:"})," TensorFlow is tightly integrated with Keras, a high-level API for building and training neural networks that is very user-friendly."]}),"\n"]}),"\n",(0,n.jsx)(o.h2,{id:"robotics-specific-vla-frameworks",children:"Robotics-Specific VLA Frameworks"}),"\n",(0,n.jsx)(o.p,{children:"While general-purpose frameworks provide the building blocks, a new generation of robotics-specific frameworks is emerging to tackle the unique challenges of VLA models. These frameworks provide tools for simulation, data collection, and deployment on real robots."}),"\n",(0,n.jsx)(o.h3,{id:"nvidia-isaac-sim-and-isaac-ros",children:"NVIDIA Isaac Sim and Isaac ROS"}),"\n",(0,n.jsx)(o.p,{children:"As we have seen in previous modules, NVIDIA's Isaac platform is a comprehensive toolkit for AI-powered robotics."}),"\n",(0,n.jsxs)(o.ul,{children:["\n",(0,n.jsxs)(o.li,{children:[(0,n.jsx)(o.strong,{children:"Isaac Sim:"})," Provides a photorealistic, physically accurate environment for training and testing VLA models on synthetic data."]}),"\n",(0,n.jsxs)(o.li,{children:[(0,n.jsx)(o.strong,{children:"Isaac ROS:"})," Offers hardware-accelerated ROS 2 packages for perception, navigation, and manipulation, which can be integrated with a VLA model."]}),"\n"]}),"\n",(0,n.jsx)(o.p,{children:"NVIDIA is actively developing VLA capabilities within the Isaac ecosystem, making it one of the most promising platforms for this technology."}),"\n",(0,n.jsx)(o.h3,{id:"googles-robotics-transformer-rt-1-and-rt-2",children:"Google's Robotics Transformer (RT-1 and RT-2)"}),"\n",(0,n.jsx)(o.p,{children:"Google has been at the forefront of VLA research with its Robotics Transformer models."}),"\n",(0,n.jsxs)(o.ul,{children:["\n",(0,n.jsxs)(o.li,{children:[(0,n.jsx)(o.strong,{children:"RT-1:"})," Was one of the first large-scale VLA models to be deployed on a real robot. It was trained on a dataset of 130,000 robot demonstrations."]}),"\n",(0,n.jsxs)(o.li,{children:[(0,n.jsx)(o.strong,{children:"RT-2:"})," Is a more recent model that is directly trained on web-scale data, allowing it to generalize to a much wider range of tasks and environments."]}),"\n"]}),"\n",(0,n.jsx)(o.p,{children:"While Google's frameworks are not as open as PyTorch or TensorFlow, their research is pushing the boundaries of what is possible with VLA models."}),"\n",(0,n.jsx)(o.h3,{id:"other-notable-frameworks",children:"Other Notable Frameworks"}),"\n",(0,n.jsxs)(o.ul,{children:["\n",(0,n.jsxs)(o.li,{children:[(0,n.jsx)(o.strong,{children:"OpenAI's Robotics Team:"}),' OpenAI has also been active in robotics research, and their work on models like GPT-4 has significant implications for the "Language" part of VLA models.']}),"\n",(0,n.jsxs)(o.li,{children:[(0,n.jsx)(o.strong,{children:"Hugging Face Transformers:"})," While not a robotics-specific framework, Hugging Face provides a vast library of pre-trained models for NLU, which are a key component of any VLA system."]}),"\n"]}),"\n",(0,n.jsx)(o.p,{children:"The field of VLA frameworks is evolving rapidly. As research progresses, we can expect to see more powerful and user-friendly tools that will make it easier for developers to build and deploy the next generation of intelligent robots."})]})}function h(e={}){const{wrapper:o}={...(0,i.R)(),...e.components};return o?(0,n.jsx)(o,{...e,children:(0,n.jsx)(c,{...e})}):c(e)}}}]);