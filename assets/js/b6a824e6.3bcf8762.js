"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[7095],{7432:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>o,toc:()=>l});const o=JSON.parse('{"id":"module-3-ai-robot-brain/pose-estimation-tracking","title":"Pose Estimation and Tracking with NVIDIA Isaac","description":"While object detection tells you what objects are in the environment, pose estimation tells you where they are in 3D space\u2014specifically, their position and orientation relative to the robot. This is a critical capability for any robot that needs to interact with its environment, such as a robotic arm that needs to grasp an object.","source":"@site/docs/module-3-ai-robot-brain/pose-estimation-tracking.mdx","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/pose-estimation-tracking","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/module-3-ai-robot-brain/pose-estimation-tracking","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"sidebar_label":"Pose Estimation and Tracking"},"sidebar":"mainSidebar","previous":{"title":"Object Detection with Isaac","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/module-3-ai-robot-brain/object-detection-isaac"},"next":{"title":"Navigation and Path Planning","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/module-3-ai-robot-brain/navigation-path-planning-isaac"}}');var n=i(4848),a=i(8453);const s={sidebar_label:"Pose Estimation and Tracking"},r="Pose Estimation and Tracking with NVIDIA Isaac",c={},l=[{value:"The Challenge of 3D Pose Estimation",id:"the-challenge-of-3d-pose-estimation",level:2},{value:"Pose Estimation with Isaac ROS CenterPose",id:"pose-estimation-with-isaac-ros-centerpose",level:2},{value:"Step-by-Step Example: Running a Pose Estimation Demo",id:"step-by-step-example-running-a-pose-estimation-demo",level:2},{value:"Object Tracking",id:"object-tracking",level:2}];function d(e){const t={code:"code",em:"em",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.header,{children:(0,n.jsx)(t.h1,{id:"pose-estimation-and-tracking-with-nvidia-isaac",children:"Pose Estimation and Tracking with NVIDIA Isaac"})}),"\n",(0,n.jsxs)(t.p,{children:["While object detection tells you ",(0,n.jsx)(t.em,{children:"what"})," objects are in the environment, ",(0,n.jsx)(t.strong,{children:"pose estimation"})," tells you ",(0,n.jsx)(t.em,{children:"where"})," they are in 3D space\u2014specifically, their position and orientation relative to the robot. This is a critical capability for any robot that needs to interact with its environment, such as a robotic arm that needs to grasp an object."]}),"\n",(0,n.jsx)(t.p,{children:"NVIDIA Isaac provides powerful, hardware-accelerated tools for both 3D pose estimation and tracking objects over time."}),"\n",(0,n.jsx)(t.h2,{id:"the-challenge-of-3d-pose-estimation",children:"The Challenge of 3D Pose Estimation"}),"\n",(0,n.jsx)(t.p,{children:"Determining the full 6-DoF (Degrees of Freedom) pose (x, y, z, roll, pitch, yaw) of an object from a 2D image is a complex problem. Traditional methods often relied on handcrafted features and complex pipelines. However, deep learning has enabled the development of highly accurate and robust pose estimation models."}),"\n",(0,n.jsx)(t.p,{children:"Isaac ROS provides ready-to-use, GPU-accelerated packages for this task, making it much easier to integrate this capability into your robot."}),"\n",(0,n.jsx)(t.h2,{id:"pose-estimation-with-isaac-ros-centerpose",children:"Pose Estimation with Isaac ROS CenterPose"}),"\n",(0,n.jsxs)(t.p,{children:["Isaac ROS includes the ",(0,n.jsx)(t.code,{children:"isaac_ros_centerpose"})," package, which uses a deep neural network to estimate the 3D pose of objects from a single RGB camera image and a 3D model of the object."]}),"\n",(0,n.jsx)(t.p,{children:"Key features of the CenterPose package include:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"High Accuracy:"})," It provides precise estimates of the object's translation and rotation."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Real-Time Performance:"})," The model is optimized with TensorRT for real-time performance on NVIDIA Jetson hardware."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Robustness:"})," It is designed to be robust to variations in lighting, occlusions, and background clutter."]}),"\n"]}),"\n",(0,n.jsx)(t.p,{children:"To use CenterPose, you need:"}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsx)(t.li,{children:"A calibrated camera."}),"\n",(0,n.jsxs)(t.li,{children:["A 3D model (e.g., in ",(0,n.jsx)(t.code,{children:".obj"})," or ",(0,n.jsx)(t.code,{children:".stl"})," format) of the target object."]}),"\n"]}),"\n",(0,n.jsx)(t.h2,{id:"step-by-step-example-running-a-pose-estimation-demo",children:"Step-by-Step Example: Running a Pose Estimation Demo"}),"\n",(0,n.jsx)(t.p,{children:"Let's walk through how to run the CenterPose demo in Isaac Sim. This example will estimate the pose of a shoe object."}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Launch Isaac Sim:"})," Start Isaac Sim from the Omniverse Launcher."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Open the Pose Estimation Scene:"})," Open the ",(0,n.jsx)(t.code,{children:"Isaac/Samples/ROS/Scenes/carter_warehouse_apriltag_pose_estimation.usd"})," scene. This scene contains a Carter robot and a shoe object on a table."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Start the ROS2 Bridge:"})," Ensure the ROS2 bridge is enabled in Isaac Sim (",(0,n.jsx)(t.code,{children:"Window > ROS Bridge"}),")."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Launch the Pose Estimation Node:"})," In a terminal, source your ROS2 workspace and launch the Isaac ROS CenterPose launch file. You will need to provide the path to the 3D model of the object.","\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-bash",children:"ros2 launch isaac_ros_centerpose isaac_ros_centerpose.launch.py mesh_file_path:=/path/to/your/shoe_model.obj\n"})}),"\n",(0,n.jsx)(t.em,{children:"(Note: You will need to download a suitable 3D model of a shoe or use one provided in the Isaac Sim assets)."})]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Visualize the Results in RViz2:"})," In another terminal, launch RViz2.","\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-bash",children:"ros2 run rviz2 rviz2 -d $(ros2 pkg prefix isaac_ros_centerpose)/rviz/isaac_ros_centerpose.rviz\n"})}),"\n","In RViz2, you will see the camera feed from the robot. A 3D bounding box and a coordinate frame will be overlaid on the shoe, representing its estimated 3D pose. The node publishes this pose as a ",(0,n.jsx)(t.code,{children:"geometry_msgs/PoseStamped"})," message."]}),"\n"]}),"\n",(0,n.jsx)(t.h2,{id:"object-tracking",children:"Object Tracking"}),"\n",(0,n.jsxs)(t.p,{children:["While pose estimation gives you an object's pose at a single point in time, ",(0,n.jsx)(t.strong,{children:"object tracking"})," allows you to maintain the identity and estimate the pose of an object as it (or the robot) moves. This is crucial for tasks like following a person or monitoring a moving obstacle."]}),"\n",(0,n.jsx)(t.p,{children:"Isaac ROS provides tracking capabilities, often building upon the detection and pose estimation outputs. For example, a common approach is to use a Kalman filter to predict the object's motion and update the prediction based on new measurements from the perception system. This results in smoother and more reliable pose estimates over time."}),"\n",(0,n.jsx)(t.p,{children:"By combining pose estimation and tracking, you can build sophisticated robotic applications that can perceive, understand, and interact with a dynamic 3D world."})]})}function h(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},8453:(e,t,i)=>{i.d(t,{R:()=>s,x:()=>r});var o=i(6540);const n={},a=o.createContext(n);function s(e){const t=o.useContext(a);return o.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:s(e.components),o.createElement(a.Provider,{value:t},e.children)}}}]);